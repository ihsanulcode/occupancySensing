{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd86cae3-69c2-470e-84b6-85907a1ff6f1",
   "metadata": {},
   "source": [
    "# Camera Based Occupancy Sensing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be9e9c-c61d-426c-9efb-2a33838cd11d",
   "metadata": {},
   "source": [
    "### Define CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00c0082-f543-468c-8415-3de89926c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "def load_resnet50(num_classes):\n",
    "    model =  models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_efficientnet_b0(num_classes):\n",
    "    model = models.efficientnet_b0(weights='EfficientNet_B0_Weights.DEFAULT')\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_mobilenet_v2(num_classes):\n",
    "    model = models.mobilenet_v2(weights='MobileNet_V2_Weights.DEFAULT')\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_mobilenet_v3_large(num_classes):\n",
    "    model = models.mobilenet_v3_large(weights='MobileNet_V3_Large_Weights.DEFAULT')\n",
    "    num_features = model.classifier[3].in_features\n",
    "    model.classifier[3] = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_mobilenet_v3_small(num_classes):\n",
    "    model = models.mobilenet_v3_small(weights='MobileNet_V3_Small_Weights.DEFAULT')\n",
    "    num_features = model.classifier[3].in_features\n",
    "    model.classifier[3] = nn.Linear(num_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5a945-4bad-4464-966a-6ed64cc0b406",
   "metadata": {},
   "source": [
    "## Model Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcd6cf4-d789-4e3a-a548-020058dd4054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe7b31b-9117-4b3a-b975-b239c96320be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-plot in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (3.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (1.9.3)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (1.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f89a3-fac7-45fe-9baa-b100b8535a1e",
   "metadata": {},
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea747d07-6a76-4e65-a060-447c9db88cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_test_dataloader(data_dir, batch_size, num_workers=4):\n",
    "    # Define transformations for the test dataset\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((244, 244)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Create the test dataset\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=data_transform)\n",
    "\n",
    "    # Create the test dataloader\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return test_loader\n",
    "\n",
    "data_dir = 'Dataset/'\n",
    "batch_size = 32\n",
    "test_loader = create_test_dataloader(data_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c5ae7f9-e7be-4244-b9a7-5e1627df10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_class, checkpoint_path, num_classes):\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "    \n",
    "def evaluate_model(model, test_loader, criterion, save_path):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)  # Output shape: [batch_size]\n",
    "            loss = criterion(outputs, labels.float())  # Convert labels to float\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Apply sigmoid activation and classify based on threshold 0.5\n",
    "            predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c4e6dd-6bb9-404d-97a8-a38af47de524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model loading functions\n",
    "model_functions = [\n",
    "    load_resnet50,\n",
    "    load_mobilenet_v3_large,\n",
    "    load_efficientnet_b0,\n",
    "    load_mobilenet_v2,\n",
    "    load_mobilenet_v3_small,\n",
    "]\n",
    "\n",
    "checkpoint_paths = [\n",
    "    'Checkpoints/resnet50/model_epoch_6.pth',\n",
    "    'Checkpoints/mobilenet_v3_large/model_epoch_3.pth',\n",
    "    'Checkpoints/efficientnet_b0/model_epoch_5.pth',\n",
    "    'Checkpoints/mobilenet_v2/model_epoch_5.pth',\n",
    "    'Checkpoints/mobilenet_v3_small/model_epoch_6.pth',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99214816-54e2-402d-a7c5-d65b36f42a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints/resnet50/model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2154, Test Accuracy: 89.25%\n",
      "Checkpoints/mobilenet_v3_large/model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3350, Test Accuracy: 94.62%\n",
      "Checkpoints/efficientnet_b0/model_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1918, Test Accuracy: 90.32%\n",
      "Checkpoints/mobilenet_v2/model_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1205, Test Accuracy: 97.85%\n",
      "Checkpoints/mobilenet_v3_small/model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8295, Test Accuracy: 88.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes = 1\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for get_model, checkpoint_path in zip(model_functions, checkpoint_paths):\n",
    "    # Load the model using the function\n",
    "    loaded_model = load_model(get_model, checkpoint_path, num_classes)\n",
    "    loaded_model = loaded_model.to(device)\n",
    "    # Evaluate the loaded model on the test set\n",
    "    print(checkpoint_path)\n",
    "    evaluate_model(loaded_model, test_loader, loss_fn, checkpoint_path.split('/')[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
